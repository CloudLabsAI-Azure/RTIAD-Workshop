목차 
문서 구조	3
소개	3
Fabric Eventstream	3
작업 1: Eventstream 만들기	3
작업 2: Eventstream 변환	7
작업 3: Eventstream 분할 및 대상 두 개 로드	10
KQL 데이터베이스에 더 많은 데이터 추가	19
작업 4: 이벤트 데이터 테이블 유효성 검사	19
작업 5: 차원 테이블에 대한 KQL 데이터베이스 바로 가기 만들기	20
요약	25
참조	26

 
 
 
 
 
 
 
 
 
 
 






문서 구조 
이 랩에서는 사용자가 수행해야 하는 단계를 보조 시각 자료의 관련 스크린샷과 함께 확인할 수 있습니다. 스크린샷에서 주황색 상자로 강조 표시된 섹션은 사용자가 특히 주목해야 하는 영역입니다. 
소개 
이 랩에서는 기존 Eventhouse로 추가 데이터를 수집하기 위해 또 다른 Eventstream을 만듭니다. KQL 데이터베이스에 추가하려는 데이터를 제어하기 위해 Eventstream 내에 변환을 포함하는 방법을 살펴보겠습니다.
이 랩을 마치면 다음 사항을 알게 됩니다. 
•	Eventstream 처리 및 변환
•	외부 데이터베이스의 데이터를 조인하기 위한 KQL 쿼리 작성
•	KQL을 사용하여 데이터를 쿼리하고 Power BI 내에서 보기
Fabric Eventstream
작업 1: Eventstream 만들기 
1.	오늘 과정을 진행하면서 사용한 Fabric 작업 영역을 엽니다.

 

2.	전자 상거래 상점과 관련하여 수집해야 할 추가 스트리밍 데이터가 있습니다. 그러나 이 Eventstream의 경우 Eventhouse에 로드하기 전에 데이터를 변환하려고 합니다. "실시간 허브"로 이동하는 대신 작업 영역에서 직접 새 Eventstream을 만들 수 있습니다. + 새로 만들기 항목 메뉴에서 새 Eventstream을 만듭니다.
 
3.	새 Eventstream 이름을 es_Fabrikam_ClickEvents로 지정하고 "향상된 기능" 옵션을 선택한 후 만들기를 클릭합니다.
 
4.	홈 리본에서 원본 추가 드롭다운을 클릭한 후 외부 원본을 선택합니다.
 
5.	이전 랩과 마찬가지로 데이터가 Python Notebook에서 스트리밍되는 Azure Event Hub에 연결합니다. “Azure Event Hubs” 타일의 “연결”을 클릭합니다. 권장 섹션에 “Azure Event Hubs”가 표시되지 않으면 “모든 원본 보기”를 선택해서 검색합니다.
 
6.	새 연결을 만듭니다.
 
7.	환경 세부 정보 페이지에서 필요한 모든 연결 설정을 복사하여 해당 필드에 붙여 넣습니다. 

Event Hub 네임스페이스: rtiadhub{username}

Event Hub: rta-iad-clicks

공유 액세스 키 이름: rti-reader

공유 액세스 키: 환경 세부 정보에서 제공
 
8.	모든 속성이 채워지면 연결을 클릭합니다.
9.	Azure Event Hub 데이터 원본 구성에서 데이터 스트림에 대한 고유한 액세스 포인트에 액세스할 수 있도록 Event Hub의 소비자 그룹을 수정해야 할 수 있습니다. 이 워크샵에서는 아래와 같이 "$Default" 값을 그대로 둘 수 있습니다
 

10.	 다음을 클릭합니다.
11.	 검토 및 만들기 창에서 모든 항목이 올바르게 구성되었는지 확인하고 추가를 클릭합니다.
 

12.	 스트림이 구성되면 Event Hub에서 들어오는 데이터 미리 보기를 볼 수 있습니다.
 
13.	 수신 중인 데이터를 검사합니다. 전자 상거래 웹 사이트에서 기록되는 이벤트에는 클릭과 노출의 두 가지 유형이 있습니다.
•	노출 - 광고 또는 제품 목록이 사용자에게 표시될 때마다 노출 이벤트가 기록됩니다. 노출은 상호 작용 여부와 관계없이 항목(광고 또는 제품)을 조회한 횟수를 측정한 값입니다.
•	클릭 - 클릭 이벤트는 사용자가 항목을 클릭하여 상호 작용할 때 기록됩니다. 클릭은 일반적으로 노출에 비해 참여 수준이 높다는 것을 나타냅니다.
기록되는 클릭 및 노출 이벤트 외에도 클릭 또는 노출이 발생한 제품, 웹 페이지가 로드된 장치와 브라우저, 페이지에 액세스한 IP 주소, 페이지를 로드하는 데 걸린 시간에 대한 세부 정보가 있습니다.
작업 2: Eventstream 변환
	
1.	이제 이 데이터 스트림을 가져와서 KQL 데이터베이스에 수집되기 전에 이 데이터에서 인사이트를 도출하려는 분석가가 쉽게 이해할 수 있는 방식으로 변환합니다. Eventstream 캔버스 내에서 이벤트 변환 개체에 대한 드롭다운을 클릭합니다.
 
2.	사용 가능한 작업 목록에서 필드 관리 옵션을 선택합니다.
 
3.	ManageFields라는 새 아이콘이 나타나면 연필 아이콘을 클릭하여 원본에서 스트림에 추가할 필드를 선택합니다.
 
4.	표시되는 플라이아웃 창에서 모든 필드 추가 옵션 버튼을 클릭합니다.
 


5.	필드 목록에서 PartitionId 필드를 선택하고 필드 위를 가리키면 나타나는 줄임표(...)를 클릭합니다.
 

6.	해당 필드 제거 옵션을 선택합니다. Event Hub에서 들어오는 이 데이터 스트림에서는 분할이 사용되지 않아 이 열은 도움이 되지 않으므로 제거합니다.
 
7.	이 스트림에 필요하지 않은 다음 필드를 모두 제거합니다.
•	userAgent
•	page_loading_seconds
•	EventProcessedUtcTime
•	EventEnqueredUtcTime

아래 이미지에 표시된 필드가 남아 있어야 합니다.
  
8.	eventDate 필드 위를 가리켜서 창 오른쪽에 줄임표(...)가 나타나면 클릭합니다.
 
9.	편집 옵션을 선택합니다.
 
10.	형식 변경 토글을 클릭하여 이 필드의 데이터 형식을 수정합니다. 원래 형식은 문자열이며 변환된 형식을 날짜/시간으로 수정해야 합니다. 완료되면 저장을 클릭합니다.
 


작업 3: Eventstream 분할 및 대상 두 개 로드
1.	분석을 위해 이 데이터 스트림을 KQL 데이터베이스에 로드할 수 있지만, 이 데이터를 사용하여 클릭 이벤트와 노출 이벤트를 구분하는 다른 방법을 사용하는 것이 좋습니다. ManageFields 변환 끝 위를 가리켜서 사용자 인터페이스에 다른 변환 활동을 추가합니다.
 
2.	사용 가능한 작업 목록에서 필터 변환을 선택합니다.

 

3.	새 변환 필터에서 연필 아이콘을 클릭합니다.

 

4.	화면 오른쪽에 표시되는 플라이아웃에서 아래 설정을 사용하여 클릭 값만 반환하는 방법을 반영하도록 필터 조건을 사용자 지정합니다. 필터 변환은 대/소문자를 구분한다는 점에 유의해야 합니다.
•	작업 이름 - 클릭
•	필터링할 필드 선택 - eventType
•	값이 다음과 같을 때 이벤트 유지 - 같음 – 클릭(중요! 이 필드는 대/소문자를 구분하는 필드이므로 이 예시에서는 모두 대문자로 입력해야 합니다.)
 
5.	저장 옵션을 선택하여 변경 내용을 유지합니다.
6.	새로 고침 버튼을 다시 클릭하여 데이터가 클릭 eventTypes로 필터링되었는지 확인합니다.
 
7.	테이블로 보내려는 유일한 행일 수 있지만 또 다른 옵션은 대신 개별 스트림 두 개를 만들어 서로 다른 정보를 두 개 이상의 테이블로 라우팅하는 것입니다. Eventstream의 홈 리본에서 이벤트 변환 드롭다운을 클릭한 후 필터를 선택합니다.
 
8.	Filter(이름은 다를 수 있음)라는 새 개체가 캔버스에 나타납니다. ManageFields스트림을 새 필터 변환에 연결해야 합니다. 한 변환의 녹색 점에서 다른 변환으로 선을 끌어서 연결합니다.
 

9.	필터의 연필 아이콘을 클릭하여 설정을 편집합니다.

 

10.	화면 오른쪽에 표시되는 플라이아웃에서 아래 값을 사용하여 노출 값만 반환하는 방법을 반영하도록 필터 조건을 사용자 지정합니다. 필터 변환은 대/소문자를 구분합니다.
•	작업 이름 - 노출
•	필터링할 필드 선택 - eventType
•	값이 다음과 같을 때 이벤트 유지 - 같음 – 노출(중요! 이 필드는 대/소문자를 구분하는 필드이므로 이 예시에서는 모두 대문자로 입력해야 합니다.)
 
11.	저장 옵션을 선택하여 변경 내용을 유지합니다.

12.	KQL 데이터베이스에 포함된 새 테이블에 데이터를 로드하기 전에 필요하지 않은 추가 열을 제거할 수 있습니다. 이 경우 "클릭" 레코드에 대해 필터링되는 데이터 스트림에서는 모든 행의 값이 동일하므로 "eventType" 열이 더 이상 필요하지 않습니다. "노출" 데이터 스트림에서도 위에서 언급한 것과 동일한 이유로 "eventType" 열을 제거할 수 있으며 이 테이블의 모든 행에 대해 비어 있는 "참조 페이지" 열도 제거할 수 있습니다.

13.	클릭 필터 작업 후 + 아이콘을 클릭합니다.
 

14.	드롭다운 메뉴에서 "필드 관리"를 선택합니다.

  

15.	연필 아이콘을 클릭하여 스트림에 추가/제거할 필드를 선택합니다.

 

16.	작업 이름을 "Manage_Clicks"로 바꿉니다. 또한 "모든 필드 추가"를 선택한 후 “eventType”을 제거합니다. 완료되면 저장을 클릭합니다.

 

17.	다음으로, 아래와 같이 "노출" 필터에 연결된 또 다른 "필드 관리" 변환을 추가해 보겠습니다.

 

18.	연필 아이콘을 클릭하여 스트림에 추가/제거할 필드를 선택합니다.

 

19.	작업 이름을 "Manage_Impressions"로 바꿉니다. 그런 다음, "모든 필드 추가"를 선택한 후 "eventType"과 "참조 페이지"를 제거합니다. "필드 관리" 변환은 다음과 같아야 합니다.

 

20.	이제 각 이벤트 유형에 대한 스트림 데이터를 정리했으므로 각 스트림을 KQL 데이터베이스의 새 테이블에 로드해야 합니다. Manage_Clicks 필드 관리 작업 후 + 아이콘을 클릭합니다.
 
21.	표시되는 드롭다운 목록에서 대상으로 이동하여 Eventhouse를 선택합니다.
 
22.	Eventhouse 대상을 위해 연필 아이콘을 클릭합니다.
 
23.	이 대상에서 다음 속성을 구성합니다.
•	대상 이름 – dbo-Clicks
•	작업 영역 - RTI_username
•	Eventhouse – eh_Fabrikam
•	KQL 데이터베이스 - eh_Fabrikam
•	Destination Table - 클릭이라는 새 테이블을 만듭니다.
 
24.	플라이아웃 아래쪽에서 저장을 클릭합니다.
25.	노출 테이블에서도 아래와 같이 구성된 다음 정보를 사용하여 동일한 작업을 수행합니다.
 
26.	변경 내용을 저장합니다.
27.	이제 이 Eventstream이 스트리밍을 시작할 준비가 되었습니다. 게시를 클릭하여 해당 스트림을 시작합니다.
 
28.	이제 Eventstream이 실행 중이면 Eventstream 사용자 인터페이스가 약간 변경되어 Event Hub에서 데이터를 스트리밍하여 해당 데이터 스트림을 변환 및 분할하고 개별 KQL 데이터베이스 테이블 두 개에 로드하고 있음을 나타냅니다.

 
KQL 데이터베이스에 더 많은 데이터 추가
작업 4: 이벤트 데이터 테이블 유효성 검사
1.	RTI_username 작업 영역으로 돌아갑니다.
2.	eh_Fabrikam KQL 데이터베이스를 엽니다.

 

3.	Eventstream이 실행 중이면 이제 KQL 데이터베이스 개요 페이지에 새 테이블 두 개가 표시됩니다. Eventstream을 잠시 실행하면 KQL 데이터베이스에 포함된 상위 테이블이 개요 페이지에 표시되고 해당 테이블에 저장된 데이터 양이 표시됩니다.
 

4.	Impressions 테이블을 클릭합니다. 이 테이블은 24시간마다 약 150만 개의 레코드를 수신합니다. 클릭 수보다 노출 수가 더 많기 때문에 노출 테이블이 이 수업의 목적상 가장 큰 테이블이 됩니다.
 

작업 5: 차원 테이블에 대한 KQL 데이터베이스 바로 가기 만들기
지금까지 스트리밍 데이터로 작업했지만, 가져온 데이터에서 인텔리전스를 도출할 수 있는 몇 가지 중요한 요소가 여전히 누락되어 있습니다. 이 작업에서는 KQL 데이터베이스 내에서 차원 테이블 역할을 할 외부 Azure SQL Database에서 데이터를 가져옵니다. 이렇게 하면 현재 스트리밍 중인 데이터를 더 잘 설명할 수 있습니다. 예를 들어 모든 테이블에는 숫자 필드인 제품 ID 형식이 포함되어 있지만 표시할 수 있는 일종의 제품 이름이 있으면 더 좋을 것입니다. 이 작업을 지원하는 데 필요한 데이터는 현재 외부 Azure SQL Database에 있습니다. 이러한 차원 테이블 중 일부에 연결하는 것이 얼마나 쉬운지 살펴보겠습니다.

1.	eh_Fabrikam 데이터베이스에서 New related item이라는 드롭다운 메뉴를 클릭합니다. 그런 다음, KQL 쿼리 집합 옵션을 선택합니다.

 

2.	KQL 쿼리 집합 이름을 Create Tables로 지정한 후 만들기 버튼을 클릭합니다.

 

3.	OneLake 데이터 허브가 열리고 선택할 수 있는 유일한 옵션은 "eh_Fabrikam" KQL 데이터베이스입니다. 이 데이터베이스를 선택하고 "연결"을 클릭합니다.
 

4.	새 인터페이스의 쿼리 창에서 한 번 클릭하고 바로 가기 키 Ctrl + A를 사용하여 모든 텍스트를 강조 표시합니다. 모든 텍스트가 강조 표시되면 이를 삭제합니다.
 
5.	빈 쿼리 창에 다음 KQL 스크립트를 입력합니다. 이 스크립트는 외부 Azure SQL Database에 대한 연결을 만들고 KQL 데이터베이스 내에서 바로 가기로 사용할 수 있도록 합니다. 바로 가기는 읽기 전용 모드로 연결되므로 KQL 데이터베이스로 수집된 스트리밍 데이터와 함께 쿼리를 보고 실행할 수 있습니다.

 
 
6.	Run 버튼을 클릭하여 스크립트를 실행합니다.
 
7.	이제 데이터베이스 탐색기 창에 Shortscuts라는 새 폴더가 표시되고 이 폴더 내에는 이 KQL 데이터베이스에 연결된 추가 테이블 두 개가 표시됩니다. 이러한 테이블은 Azure SQL Database 내에 존재하지만 이제 실행한 스크립트를 통해 해당 테이블을 이 KQL 데이터베이스에 연결하여 InternetSales 및 이벤트 테이블과 조인할 수 있습니다.
 
8.	이제 데이터베이스에 대한 차원적 품질이 있으므로 질문에 답하고 보고서 소비자에게 더 많은 컨텍스트를 제공할 수 있으며 비즈니스 전반에 걸친 인사이트를 기반으로 테이블을 쿼리합니다. 다음 KQL 쿼리를 실행하여 그중 하나를 확인합니다.

 

9.	이제 회사에서 판매한 개별 제품에 대한 값이 쿼리 결과에 표시됩니다.

 

10.	쿼리가 강조 표시된 상태에서 도구 모음에 있는 Power BI 보고서 작성 버튼을 클릭합니다.

 

11.	이렇게 하면 KQL 데이터베이스에 포함된 데이터를 사용하여 Power BI 보고서를 만들 수 있습니다. 잠시 동안 자유롭게 살펴보되 아직은 이 데이터로 보고서를 만들 필요가 없습니다. 계속 진행할 준비가 되면 오른쪽 위 모서리에 있는 X 버튼을 클릭합니다.

 

12.	eh_Fabrikam KQL 데이터베이스로 다시 이동합니다.
 

13.	eh_Fabrikam 탐색 창에서 Shortscuts 옵션을 클릭합니다. 그러면 이 KQL 데이터베이스에 대해 만든 바로 가기가 모두 표시됩니다. 이러한 바로 가기는 Azure SQL 외부 테이블 구문을 사용하는 클래식 Azure Data Explorer 외부 테이블로 간주되며 Fabric 내의 KQL 데이터베이스에서도 지원되는 OneLake, ADLS 또는 S3 바로 가기와는 다르게 생성됩니다.
 

요약
이 랩에서는 또 다른 데이터 스트림을 만들었지만, Fabric에서 Eventstream의 사용자 인터페이스를 사용하여 스트림을 변환할 수 있었습니다. 데이터를 개별 테이블 두 개에 로드하여 마케팅, 광고, 분석 목적으로 전자 상거래 시스템에서 발생한 모든 클릭과 노출을 추적할 수 있었습니다. 또한 KQL 쿼리 집합 외부 테이블 기능을 사용하여 외부 Azure SQL Database 바로 가기를 만들었습니다. 이제 KQL 데이터베이스 내에서 판매와 클릭 컨텍스트를 더 잘 이해할 수 있는 몇 가지 차원이 있습니다.




참조 
Fabric Real-Time Intelligence in a Day(RTIIAD)는 Microsoft Fabric에서 사용할 수 있는 몇 가지 주요 기능을 소개합니다. 
서비스의 메뉴에 있는 도움말(?) 섹션에는 유용한 리소스로 연결되는 링크가 있습니다. 
 
아래는 Microsoft Fabric의 다음 단계에 도움이 되는 몇 가지 추가 자료입니다. 
•	https://aka.ms/Fabric-Hero-Blog-Ignite23Microsoft Fabric GA 발표 전문을 블로그 포스트로 읽기
•	가이드 투어https://aka.ms/Fabric-GuidedTour로 Fabric 탐색
•	Microsoft Fabric 무료 평가판 신청
•	Microsoft Fabric 웹 사이트 방문
•	Fabric 학습 모듈https://aka.ms/learn-fabric을 탐색해서 새로운 기술 익히기
•	Fabric 기술 문서 검토
•	Fabric 시작하기 무료 e북 읽기
•	https://aka.ms/fabric-communityFabric 커뮤니티https://aka.ms/fabric-community에 가입하여 질문을 게시하고 피드백을 공유하며 다른 사람들로부터 배우기 
더 많은 심층 Fabric 환경 발표 블로그 포스트 읽기: 
•	Fabric 블로그의 Data Factory 환경 
•	Fabric 블로그의 Synapse Data Engineering 환경  
•	Fabric 블로그의 Synapse Data Science 환경  
•	Fabric 블로그의 Synapse Data Warehousing 환경  
•	Fabric 블로그의 Real-Time Intelligence 환경 
•	Power BI 발표 블로그 
•	Fabric 블로그의 Data Activator 환경  
•	Fabric 블로그의 관리 및 거버넌스 
•	Fabric 블로그의 OneLake 
•	Dataverse 및 Microsoft Fabric 통합 블로그 
 
© 2024 Microsoft Corporation. All rights reserved. 
이 데모/랩을 사용하면 다음 조건에 동의하게 됩니다. 
이 데모/랩에 설명된 기술/기능은 학습 환경을 제공하고 사용자 의견을 얻기 위해 Microsoft Corporation에서 제공합니다. 데모/랩을 통해서만 이러한 기술적 특성과 기능을 평가하고 사용자 의견을 Microsoft에 제시할 수 있습니다. 다른 용도로는 사용할 수 없습니다. 이 데모/랩 또는 그 일부에 대해 수정, 복사, 배포, 전송, 표시, 수행, 재현, 게시, 라이선스 허여, 파생 작업 생성, 양도 또는 판매할 수 없습니다. 
추가 복제 또는 재배포를 위한 다른 서버 또는 위치에 대한 데모/랩(또는 그 일부)의 복사 또는 재현은 명시적으로 금지됩니다. 
이 데모/랩은 위에서 명시한 목적을 위해 복잡한 설정 또는 설치가 없는 시뮬레이션된 환경에서 잠재적인 새로운 기능과 개념을 포함하여 특정 소프트웨어 기술/제품의 특성 및 기능을 제공합니다. 이 데모/랩에서 서술된 기술/개념은 전체 기능을 나타내지 않을 수 있으며, 최종 버전이 작동하지 않을 수도 있습니다. 또한 해당 기능 또는 개념의 최종 버전을 릴리스하지 않을 수도 있습니다. 또한 실제 환경에서 이러한 특성과 기능을 사용한 경험이 다를 수도 있습니다. 
피드백. 이 데모/랩에서 서술된 기술적 특성, 기능 및/또는 개념에 대한 피드백을 Microsoft에 제시하면 Microsoft는 이 피드백을 어떤 방식과 목적으로든 무료로 사용, 공유 및 상용화할 수 있습니다. 또한 제품, 기술 및 서비스에서 피드백이 포함된 Microsoft 소프트웨어 또는 서비스의 특정 부분을 사용하거나 인터페이스하는 데 필요한 모든 특허권을 제3자에게 무료로 제공합니다. Microsoft에서 사용자 의견을 포함하기 때문에 Microsoft에서 해당 소프트웨어 또는 설명서의 사용을 인가해야 하는 라이선스에 종속된 사용자 의견은 제공할 수 없습니다. 이러한 권리는 본 계약에 의거하여 유효합니다. 
Microsoft Corporation은 이에 따라 명시적, 묵시적 또는 법적 특정 목적에의 적합성, 권리 및 비침해 여부에 관계없이 상품성에 대한 모든 보증과 조건을 포함하여 데모/랩과 관련된 모든 보증 및 조건을부인합니다. Microsoft는 어떤 목적으로든 결과의 정확성, 데모/랩의 사용으로 파생된 출력 또는 데모/랩에 포함된 정보의 적합성과 관련하여 어떠한 보증이나 진술도 하지 않습니다. 
고지 사항
이 데모/랩에는 Microsoft Power BI의 새로운 기능 및 향상된 기능 중 일부만 포함되어 있습니다. 일부 기능은 제품의 향후 릴리스에서 변경될 수 있습니다. 이 데모/랩에서는 새로운 기능 모두가 아닌 일부에 대해 학습하게 됩니다. 
